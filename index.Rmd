---
title: "Practical Machine Learning - Predicting Activity Class"
author: "Andrey Budish"
date: "22 December 2017"
output: 
  html_document: 
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```

## Background

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, the goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here:  

<http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har>


## Task
Six young health participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E).  

**The task is to predict the class of the performed activity.**

## Info about computer
```{r comp_info}
sessionInfo()
```

## Downloading and reading files
```{r download_read}
# Download training and test set
dlMethod <- "curl" # sets default for OSX / Linux

train_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
test_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

# Making download reproducible on any system
if(substr(Sys.getenv("OS"),1,7) == "Windows") dlMethod <- "wininet"

# Checking file existance and dowloading
if(!file.exists("pml-training.csv")) {
    download.file(train_url,
                  "pml-training.csv",  # stores file in R working directory
                  method=dlMethod # use OS-appropriate method
    )
}

if(!file.exists("pml-testing.csv")) {
    download.file(test_url,
                  "pml-testing.csv", 
                  method=dlMethod
    )
}

# Read train and test set data
library(readr)
train <- read_csv("pml-training.csv", na = c("", "NA", "#DIV/0!"))
test <- read_csv("pml-testing.csv", na = c("", "NA"))
```

## Data Cleaning
``` {r cleaning}
library(dplyr, warn.conflicts = F)
# Getting rid of column showing number of rows
train <- train[, -1]
test <- test[, -1]

# Change row types in bulk
numeric_cols <- 6:158
train[, numeric_cols] <- train[, numeric_cols] %>% apply(MARGIN = 2, FUN = function(x) as.numeric(x))
test[, numeric_cols] <- test[, numeric_cols] %>% apply(MARGIN = 2, FUN = function(x) as.numeric(x))

# Find columns in test set where all values are NAs
cols_all_NAs <- sapply(test, function(x) all(is.na(x)))

# Get rid of these columns in both test and train set
test <- test[, !cols_all_NAs]
train <- train[, !cols_all_NAs]

# create two vectors to compare column types in train and test, except the last column
train_col_classes <- sapply(train[, -59], class)
test_col_classes <- sapply(test[, -59], class)

# Compare columns classes
identical(train_col_classes, test_col_classes) # they are identical

# Change response variable type to factor
train$classe <- as.factor(train$classe)

# Lets split train set into dependant variables and independant variable
train_x <- train[, -59]
train_y <- train$classe

# As for the test set, we don't need the last column
test_x <- test[, -59]

## Next - we will combine two sets with dependant variables for further data cleaning
# Save the row number for later split into train and test
split_row <- nrow(train_x)

# Combine two sets for further cleanning
data <- bind_rows(train_x, test_x)

# Change date column to an appropriate format
library(lubridate, warn.conflicts = F)
data$cvtd_timestamp <- dmy_hm(data$cvtd_timestamp)

# Remove other unnessary date columns
data$raw_timestamp_part_1 <- NULL
data$raw_timestamp_part_2 <- NULL

# Change char to factor columns
data$user_name <- as.factor(data$user_name)
data$new_window <- as.factor(data$new_window)

# Create a weekday variable from date
data$weekday <- weekdays(data$cvtd_timestamp)
data$weekday <- as.factor(data$weekday)

# Delete date column
data$cvtd_timestamp <- NULL

# Split data back to train_x and test_x
train_x <- data[1:split_row, ]
test_x <- data[(split_row + 1):nrow(data), ]

# Recreate train test back, because we will need it in modeling
train <- bind_cols(train_x, classe=train_y)
```

## Modeling
Since we have a multiclass classification problem here we will use random forest algorithm to predict classes of activities:
```{r modeling}
# Load ml libraries
library(caret, warn.conflicts = F)
library(ranger)

# Create custom grids with varing number of splits in each tree
myGrid <- expand.grid(mtry = c(2, 5, 10, 20, 30), splitrule = "gini")

# We will use near zero variance technique to get rid of such variables,
    # and for missing values we will use median imputation
# We will use random forest algorithm from ranger package
set.seed(42)
model_rf <- train(classe ~ ., data = train,
                  method = "ranger",
                  na.action = "na.pass",
                  preProcess = c("nzv","medianImpute"),
                  trControl = trainControl(method = "cv", number = 5, verbose = TRUE),
                  tuneGrid = myGrid
                  )
```

### Model summary
```{r summary_model}
model_rf
```
Model shows highest accuracy with number of splits equal to 20  

### Plotting the model
Plot below shows how accuracy changes with increasing number of splits in trees:
```{r plot_model}
plot(model_rf)
```

### Predicting on test set
Test set contains only 20 observations. 
We will use our model to predict the classes of activities:
```{r predict}
predicted <- predict(model_rf, newdata = test_x, na.action = "na.pass")
names(predicted) <- 1:20
predicted
```